{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e33f06",
   "metadata": {},
   "source": [
    "# Dataset & Preprocessing\n",
    "\n",
    "Sama seperti boolean retrieval (menggunakan satu directory yang sama) --> Hasil preprocess ada di ../data/documents.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c06b9",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c77155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict, Tuple\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561cf097",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../preprocessing')\n",
    "from preprocessor import DocumentPreprocessor # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38398ea8",
   "metadata": {},
   "source": [
    "# Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d27a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(filepath: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Load documents from JSONL file\"\"\"\n",
    "    documents = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            doc = json.loads(line.strip())\n",
    "            documents.append(doc)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20cd5017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 preprocessed documents\n",
      "\n",
      "documents:\n",
      "d1: cat chase small mous garden\n",
      "d2: friendli dog play fetch river\n",
      "d3: bm25 rank function wide use search engin\n",
      "d4: boolean retriev use logic oper like\n",
      "d5: tfidf weight term frequenc rariti\n",
      "d6: neural retriev use dens embed semant search\n",
      "d7: dog cat slept couch\n",
      "d8: librari host workshop inform retriev\n",
      "d9: student implement bm25 compar tfidf\n",
      "d10: chef roast chicken rosemari garlic\n",
      "d11: black cat cross old stone bridg night\n",
      "d12: dog loyal companion long hike\n",
      "d13: dataset contain fifteen short sentenc test\n",
      "d14: rerank model reorder bm25 candid use transform\n",
      "d15: dog snif cat ignor mous\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents('../data/documents.jsonl')\n",
    "print(f\"Loaded {len(documents)} preprocessed documents\")\n",
    "print(\"\\ndocuments:\")\n",
    "for doc in documents:\n",
    "    print(f\"{doc['id']}: {doc['contents']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759f906",
   "metadata": {},
   "source": [
    "# Build Vocabulary and Calculate term frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb60f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(documents: List[Dict[str, str]]) -> Tuple[List[str], Dict[str, Dict[str, int]]]:\n",
    "    \"\"\"\n",
    "    Build vocabulary from documents and calculate term frequencies\n",
    "    Returns: (vocabulary, term_freq_per_doc)\n",
    "    \"\"\"\n",
    "    vocabulary = set()\n",
    "    term_freq_per_doc = {}\n",
    "    \n",
    "    for doc in documents:\n",
    "        doc_id = doc['id']\n",
    "        terms = doc['contents'].split()\n",
    "        \n",
    "        # Count term frequencies in this document\n",
    "        term_freq = Counter(terms)\n",
    "        term_freq_per_doc[doc_id] = term_freq\n",
    "        \n",
    "        # Add terms to vocabulary\n",
    "        vocabulary.update(terms)\n",
    "    \n",
    "    return sorted(list(vocabulary)), term_freq_per_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb39f2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 68\n",
      "\n",
      "terms: ['black', 'bm25', 'boolean', 'bridg', 'candid', 'cat', 'chase', 'chef', 'chicken', 'companion', 'compar', 'contain', 'couch', 'cross', 'dataset', 'dens', 'dog', 'embed', 'engin', 'fetch', 'fifteen', 'frequenc', 'friendli', 'function', 'garden', 'garlic', 'hike', 'host', 'ignor', 'implement', 'inform', 'librari', 'like', 'logic', 'long', 'loyal', 'model', 'mous', 'neural', 'night', 'old', 'oper', 'play', 'rank', 'rariti', 'reorder', 'rerank', 'retriev', 'river', 'roast', 'rosemari', 'search', 'semant', 'sentenc', 'short', 'slept', 'small', 'snif', 'stone', 'student', 'term', 'test', 'tfidf', 'transform', 'use', 'weight', 'wide', 'workshop']\n",
      "\n",
      "Term frequencies for all documents:\n",
      "\n",
      "d1:\n",
      "  {'cat': 1, 'chase': 1, 'small': 1, 'mous': 1, 'garden': 1}\n",
      "\n",
      "d2:\n",
      "  {'friendli': 1, 'dog': 1, 'play': 1, 'fetch': 1, 'river': 1}\n",
      "\n",
      "d3:\n",
      "  {'bm25': 1, 'rank': 1, 'function': 1, 'wide': 1, 'use': 1, 'search': 1, 'engin': 1}\n",
      "\n",
      "d4:\n",
      "  {'boolean': 1, 'retriev': 1, 'use': 1, 'logic': 1, 'oper': 1, 'like': 1}\n",
      "\n",
      "d5:\n",
      "  {'tfidf': 1, 'weight': 1, 'term': 1, 'frequenc': 1, 'rariti': 1}\n",
      "\n",
      "d6:\n",
      "  {'neural': 1, 'retriev': 1, 'use': 1, 'dens': 1, 'embed': 1, 'semant': 1, 'search': 1}\n",
      "\n",
      "d7:\n",
      "  {'dog': 1, 'cat': 1, 'slept': 1, 'couch': 1}\n",
      "\n",
      "d8:\n",
      "  {'librari': 1, 'host': 1, 'workshop': 1, 'inform': 1, 'retriev': 1}\n",
      "\n",
      "d9:\n",
      "  {'student': 1, 'implement': 1, 'bm25': 1, 'compar': 1, 'tfidf': 1}\n",
      "\n",
      "d10:\n",
      "  {'chef': 1, 'roast': 1, 'chicken': 1, 'rosemari': 1, 'garlic': 1}\n",
      "\n",
      "d11:\n",
      "  {'black': 1, 'cat': 1, 'cross': 1, 'old': 1, 'stone': 1, 'bridg': 1, 'night': 1}\n",
      "\n",
      "d12:\n",
      "  {'dog': 1, 'loyal': 1, 'companion': 1, 'long': 1, 'hike': 1}\n",
      "\n",
      "d13:\n",
      "  {'dataset': 1, 'contain': 1, 'fifteen': 1, 'short': 1, 'sentenc': 1, 'test': 1}\n",
      "\n",
      "d14:\n",
      "  {'rerank': 1, 'model': 1, 'reorder': 1, 'bm25': 1, 'candid': 1, 'use': 1, 'transform': 1}\n",
      "\n",
      "d15:\n",
      "  {'dog': 1, 'snif': 1, 'cat': 1, 'ignor': 1, 'mous': 1}\n"
     ]
    }
   ],
   "source": [
    "vocabulary, term_freq_per_doc = build_vocabulary(documents)\n",
    "\n",
    "print(f\"Vocabulary size: {len(vocabulary)}\")\n",
    "print(f\"\\nterms: {vocabulary}\")\n",
    "print(f\"\\nTerm frequencies for all documents:\")\n",
    "\n",
    "for i in range(1, 16):\n",
    "    doc_id = f'd{i}'\n",
    "    print(f\"\\n{doc_id}:\")\n",
    "    print(f\"  {dict(term_freq_per_doc[doc_id])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0e8288",
   "metadata": {},
   "source": [
    "# Calculate Document Frequency (DF) and IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2882d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_df_idf(vocabulary: List[str], documents: List[Dict[str, str]]) -> Tuple[Dict[str, int], Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Calculate document frequency and inverse document frequency\n",
    "    \"\"\"\n",
    "    N = len(documents)  # Total number of documents\n",
    "    df = defaultdict(int)  # Document frequency for each term\n",
    "    \n",
    "    # Count in how many documents each term appears\n",
    "    for doc in documents:\n",
    "        terms = set(doc['contents'].split())  # Use set to count each term once per document\n",
    "        for term in terms:\n",
    "            df[term] += 1\n",
    "    \n",
    "    # Calculate IDF\n",
    "    idf = {}\n",
    "    for term in vocabulary:\n",
    "        idf[term] = math.log10(N / df[term]) if df[term] > 0 else 0\n",
    "    \n",
    "    return dict(df), idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c7123a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, idf = calculate_df_idf(vocabulary, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b31d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Frequency (DF) and IDF for sample terms:\n",
      "\n",
      "Term            DF    IDF       \n",
      "------------------------------\n",
      "black           1     1.1761    \n",
      "bm25            3     0.6990    \n",
      "boolean         1     1.1761    \n",
      "bridg           1     1.1761    \n",
      "candid          1     1.1761    \n",
      "cat             4     0.5740    \n",
      "chase           1     1.1761    \n",
      "chef            1     1.1761    \n",
      "chicken         1     1.1761    \n",
      "companion       1     1.1761    \n",
      "compar          1     1.1761    \n",
      "contain         1     1.1761    \n",
      "couch           1     1.1761    \n",
      "cross           1     1.1761    \n",
      "dataset         1     1.1761    \n",
      "dens            1     1.1761    \n",
      "dog             4     0.5740    \n",
      "embed           1     1.1761    \n",
      "engin           1     1.1761    \n",
      "fetch           1     1.1761    \n",
      "fifteen         1     1.1761    \n",
      "frequenc        1     1.1761    \n",
      "friendli        1     1.1761    \n",
      "function        1     1.1761    \n",
      "garden          1     1.1761    \n",
      "garlic          1     1.1761    \n",
      "hike            1     1.1761    \n",
      "host            1     1.1761    \n",
      "ignor           1     1.1761    \n",
      "implement       1     1.1761    \n",
      "inform          1     1.1761    \n",
      "librari         1     1.1761    \n",
      "like            1     1.1761    \n",
      "logic           1     1.1761    \n",
      "long            1     1.1761    \n",
      "loyal           1     1.1761    \n",
      "model           1     1.1761    \n",
      "mous            2     0.8751    \n",
      "neural          1     1.1761    \n",
      "night           1     1.1761    \n",
      "old             1     1.1761    \n",
      "oper            1     1.1761    \n",
      "play            1     1.1761    \n",
      "rank            1     1.1761    \n",
      "rariti          1     1.1761    \n",
      "reorder         1     1.1761    \n",
      "rerank          1     1.1761    \n",
      "retriev         3     0.6990    \n",
      "river           1     1.1761    \n",
      "roast           1     1.1761    \n",
      "rosemari        1     1.1761    \n",
      "search          2     0.8751    \n",
      "semant          1     1.1761    \n",
      "sentenc         1     1.1761    \n",
      "short           1     1.1761    \n",
      "slept           1     1.1761    \n",
      "small           1     1.1761    \n",
      "snif            1     1.1761    \n",
      "stone           1     1.1761    \n",
      "student         1     1.1761    \n",
      "term            1     1.1761    \n",
      "test            1     1.1761    \n",
      "tfidf           2     0.8751    \n",
      "transform       1     1.1761    \n",
      "use             4     0.5740    \n",
      "weight          1     1.1761    \n",
      "wide            1     1.1761    \n",
      "workshop        1     1.1761    \n"
     ]
    }
   ],
   "source": [
    "print(\"Document Frequency (DF) and IDF for sample terms:\\n\")\n",
    "print(f\"{'Term':<15} {'DF':<5} {'IDF':<10}\")\n",
    "print(\"-\" * 30)\n",
    "for term in vocabulary:\n",
    "    print(f\"{term:<15} {df[term]:<5} {idf[term]:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6505c00e",
   "metadata": {},
   "source": [
    "# Calculate TF-IDF weights for all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56349e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf_idf(vocabulary: List[str], \n",
    "                     term_freq_per_doc: Dict[str, Dict[str, int]], \n",
    "                     idf: Dict[str, float],\n",
    "                     documents: List[Dict[str, str]]) -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Calculate TF-IDF weights for all documents\n",
    "    TF = 1 + log10(tf) if tf > 0, else 0\n",
    "    TF-IDF = TF * IDF\n",
    "    \"\"\"\n",
    "    tfidf_weights = {}\n",
    "    \n",
    "    for doc in documents:\n",
    "        doc_id = doc['id']\n",
    "        tfidf_weights[doc_id] = {}\n",
    "        \n",
    "        for term in vocabulary:\n",
    "            tf_raw = term_freq_per_doc[doc_id].get(term, 0)\n",
    "            \n",
    "            # Calculate normalized TF\n",
    "            if tf_raw > 0:\n",
    "                tf = 1 + math.log10(tf_raw)\n",
    "            else:\n",
    "                tf = 0\n",
    "            \n",
    "            # Calculate TF-IDF\n",
    "            tfidf = tf * idf[term]\n",
    "            tfidf_weights[doc_id][term] = tfidf\n",
    "    \n",
    "    return tfidf_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f77f9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_weights = calculate_tf_idf(vocabulary, term_freq_per_doc, idf, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdcebf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Weights Table:\n",
      "\n",
      "Term           d1          d2          d3          d4          d5          d6          d7          d8          d9          d10         d11         d12         d13         d14         d15         \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "black          0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       \n",
      "bm25           0.000       0.000       0.699       0.000       0.000       0.000       0.000       0.000       0.699       0.000       0.000       0.000       0.000       0.699       0.000       \n",
      "boolean        0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "bridg          0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       \n",
      "candid         0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       \n",
      "cat            0.574       0.000       0.000       0.000       0.000       0.000       0.574       0.000       0.000       0.000       0.574       0.000       0.000       0.000       0.574       \n",
      "chase          1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "chef           0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       \n",
      "chicken        0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       \n",
      "companion      0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       \n",
      "compar         0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "contain        0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       \n",
      "couch          0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "cross          0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       \n",
      "dataset        0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       \n",
      "dens           0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "dog            0.000       0.574       0.000       0.000       0.000       0.000       0.574       0.000       0.000       0.000       0.000       0.574       0.000       0.000       0.574       \n",
      "embed          0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "engin          0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "fetch          0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "fifteen        0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       \n",
      "frequenc       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "friendli       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "function       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "garden         1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "garlic         0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       \n",
      "hike           0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       \n",
      "host           0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "ignor          0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       \n",
      "implement      0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "inform         0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "librari        0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "like           0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "logic          0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "long           0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       \n",
      "loyal          0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       \n",
      "model          0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       \n",
      "mous           0.875       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.875       \n",
      "neural         0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "night          0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       \n",
      "old            0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       \n",
      "oper           0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "play           0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "rank           0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "rariti         0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "reorder        0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       \n",
      "rerank         0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       \n",
      "retriev        0.000       0.000       0.000       0.699       0.000       0.699       0.000       0.699       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "river          0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "roast          0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       \n",
      "rosemari       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       \n",
      "search         0.000       0.000       0.875       0.000       0.000       0.875       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "semant         0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "sentenc        0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       \n",
      "short          0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       \n",
      "slept          0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "small          1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "snif           0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       \n",
      "stone          0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       \n",
      "student        0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "term           0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "test           0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       \n",
      "tfidf          0.000       0.000       0.000       0.000       0.875       0.000       0.000       0.000       0.875       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "transform      0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       \n",
      "use            0.000       0.000       0.574       0.574       0.000       0.574       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.574       0.000       \n",
      "weight         0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "wide           0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n",
      "workshop       0.000       0.000       0.000       0.000       0.000       0.000       0.000       1.176       0.000       0.000       0.000       0.000       0.000       0.000       0.000       \n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF Weights Table:\\n\")\n",
    "docs = ['d1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'd10', 'd11', 'd12', 'd13', 'd14', 'd15']\n",
    "\n",
    "print(f\"{'Term':<15}\", end=\"\")\n",
    "for doc_id in docs:\n",
    "    print(f\"{doc_id:<12}\", end=\"\")\n",
    "print()\n",
    "print(\"-\" * 190)\n",
    "\n",
    "for term in vocabulary:\n",
    "    print(f\"{term:<15}\", end=\"\")\n",
    "    for doc_id in docs:\n",
    "        weight = tfidf_weights[doc_id][term]\n",
    "        print(f\"{weight:<12.3f}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e13f1f",
   "metadata": {},
   "source": [
    "# Create Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cf35b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document_vectors(vocabulary: List[str], \n",
    "                           tfidf_weights: Dict[str, Dict[str, float]],\n",
    "                           documents: List[Dict[str, str]]) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Create document vectors from TF-IDF weights\n",
    "    Each document is represented as a vector of dimension len(vocabulary)\n",
    "    \"\"\"\n",
    "    doc_vectors = {}\n",
    "    \n",
    "    for doc in documents:\n",
    "        doc_id = doc['id']\n",
    "        vector = np.array([tfidf_weights[doc_id][term] for term in vocabulary])\n",
    "        doc_vectors[doc_id] = vector\n",
    "    \n",
    "    return doc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "510d5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = create_document_vectors(vocabulary, tfidf_weights, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb8d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Vectors (first 3 documents):\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "d1:\n",
      "  Shape: (68,)\n",
      "  Non-zero elements: 5\n",
      "  Non-zero weights:\n",
      "    cat                  -> 0.5740\n",
      "    chase                -> 1.1761\n",
      "    garden               -> 1.1761\n",
      "    mous                 -> 0.8751\n",
      "    small                -> 1.1761\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "d2:\n",
      "  Shape: (68,)\n",
      "  Non-zero elements: 5\n",
      "  Non-zero weights:\n",
      "    dog                  -> 0.5740\n",
      "    fetch                -> 1.1761\n",
      "    friendli             -> 1.1761\n",
      "    play                 -> 1.1761\n",
      "    river                -> 1.1761\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "d3:\n",
      "  Shape: (68,)\n",
      "  Non-zero elements: 7\n",
      "  Non-zero weights:\n",
      "    bm25                 -> 0.6990\n",
      "    engin                -> 1.1761\n",
      "    function             -> 1.1761\n",
      "    rank                 -> 1.1761\n",
      "    search               -> 0.8751\n",
      "    use                  -> 0.5740\n",
      "    wide                 -> 1.1761\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Document Vectors (first 3 documents):\\n\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for doc_id in ['d1', 'd2', 'd3']:\n",
    "    vector = doc_vectors[doc_id]\n",
    "    \n",
    "    # Show basic info\n",
    "    print(f\"\\n{doc_id}:\")\n",
    "    print(f\"  Shape: {vector.shape}\") # -> 68 dimensi\n",
    "    print(f\"  Non-zero elements: {np.count_nonzero(vector)}\")\n",
    "    \n",
    "    # Show non-zero dimensions only (menampilkan 68 terlalu banyak)\n",
    "    non_zero_indices = np.nonzero(vector)[0]\n",
    "    if len(non_zero_indices) > 0:\n",
    "        print(f\"  Non-zero weights:\")\n",
    "        for idx in non_zero_indices:\n",
    "            term = vocabulary[idx]\n",
    "            weight = vector[idx]\n",
    "            print(f\"    {term:20s} -> {weight:.4f}\")\n",
    "    else:\n",
    "        print(f\"  All zeros\")\n",
    "    \n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34a9215",
   "metadata": {},
   "source": [
    "# Preprocessor used again for query processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d93eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DocumentPreprocessor()\n",
    "\n",
    "def process_query(query: str, \n",
    "                 vocabulary: List[str], \n",
    "                 idf: Dict[str, float],\n",
    "                 preprocessor: DocumentPreprocessor) -> Tuple[np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Process query and convert to TF-IDF vector\n",
    "    Steps:\n",
    "    1. Preprocess query (lowercase, remove punctuation, stopwords, stemming)\n",
    "    2. Calculate term frequency\n",
    "    3. Normalize TF using 1 + log10(tf)\n",
    "    4. Multiply by IDF\n",
    "    5. Create query vector with same dimensions as document vectors\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[np.ndarray, List[str]]: (query_vector, query_terms)\n",
    "    \"\"\"\n",
    "    # Preprocess query\n",
    "    query_terms = preprocessor.preprocess_text(query)\n",
    "    print(f\"Original query: {query}\")\n",
    "    print(f\"Preprocessed query: {' '.join(query_terms)}\")\n",
    "    \n",
    "    # Calculate term frequency in query\n",
    "    query_tf = Counter(query_terms)\n",
    "    \n",
    "    # Calculate TF-IDF for query\n",
    "    query_tfidf = {}\n",
    "    for term in vocabulary:\n",
    "        tf_raw = query_tf.get(term, 0)\n",
    "        \n",
    "        # Normalize TF\n",
    "        if tf_raw > 0:\n",
    "            tf = 1 + math.log10(tf_raw)\n",
    "        else:\n",
    "            tf = 0\n",
    "        \n",
    "        # Calculate TF-IDF\n",
    "        query_tfidf[term] = tf * idf.get(term, 0)\n",
    "    \n",
    "    # Create query vector\n",
    "    query_vector = np.array([query_tfidf[term] for term in vocabulary])\n",
    "    \n",
    "    return query_vector, query_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9af8b66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: library workshop\n",
      "Preprocessed query: librari workshop\n",
      "\n",
      "Query vector shape: (68,)\n",
      "Non-zero elements in query vector: 2\n"
     ]
    }
   ],
   "source": [
    "test_query = \"library workshop\"\n",
    "query_vector, query_terms = process_query(test_query, vocabulary, idf, preprocessor)\n",
    "print(f\"\\nQuery vector shape: {query_vector.shape}\")\n",
    "print(f\"Non-zero elements in query vector: {np.count_nonzero(query_vector)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f1e05",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66cc40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors\n",
    "    cos_sim = (vec1 Â· vec2) / (||vec1|| * ||vec2||)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dot_product / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bdfb7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_rank(query: str, \n",
    "                   vocabulary: List[str],\n",
    "                   idf: Dict[str, float],\n",
    "                   doc_vectors: Dict[str, np.ndarray],\n",
    "                   preprocessor: DocumentPreprocessor,\n",
    "                   documents: List[Dict[str, str]],\n",
    "                   top_k: int = 5) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Search and rank documents by cosine similarity with query\n",
    "    \"\"\"\n",
    "    print(f\"Searching for: {query}\")\n",
    "    \n",
    "    # Process query to vector\n",
    "    query_vector, query_terms = process_query(query, vocabulary, idf, preprocessor)\n",
    "    \n",
    "    if len(query_terms) == 0:\n",
    "        print(\"âš ï¸  No valid terms after preprocessing\")\n",
    "        return []\n",
    "    \n",
    "    # Calculate cosine similarity with all documents\n",
    "    similarities = []\n",
    "    for doc_id, doc_vector in doc_vectors.items():\n",
    "        sim = cosine_similarity(query_vector, doc_vector)\n",
    "        similarities.append((doc_id, sim))\n",
    "    \n",
    "    # Sort by similarity (descending)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Filter out zero similarities and get top k\n",
    "    results = [(doc_id, sim) for doc_id, sim in similarities if sim > 0][:top_k]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60309e0a",
   "metadata": {},
   "source": [
    "# Test Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e5368e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: library workshop\n",
      "Original query: library workshop\n",
      "Preprocessed query: librari workshop\n",
      "\n",
      "Top 1 results:\n",
      "Rank   Doc ID   Score        Content\n",
      "--------------------------------------------------------------------------------\n",
      "1      d8       0.6778       librari host workshop inform retriev\n",
      "\n",
      "Searching for: dog cat\n",
      "Original query: dog cat\n",
      "Preprocessed query: dog cat\n",
      "\n",
      "Top 5 results:\n",
      "Rank   Doc ID   Score        Content\n",
      "--------------------------------------------------------------------------------\n",
      "1      d7       0.4386       dog cat slept couch\n",
      "2      d15      0.3965       dog snif cat ignor mous\n",
      "3      d1       0.1772       cat chase small mous garden\n",
      "4      d2       0.1676       friendli dog play fetch river\n",
      "5      d12      0.1676       dog loyal companion long hike\n",
      "\n",
      "Searching for: search retrieval\n",
      "Original query: search retrieval\n",
      "Preprocessed query: search retriev\n",
      "\n",
      "Top 4 results:\n",
      "Rank   Doc ID   Score        Content\n",
      "--------------------------------------------------------------------------------\n",
      "1      d6       0.4198       neural retriev use dens embed semant search\n",
      "2      d3       0.2563       bm25 rank function wide use search engin\n",
      "3      d8       0.1778       librari host workshop inform retriev\n",
      "4      d4       0.1731       boolean retriev use logic oper like\n",
      "\n",
      "Searching for: bm25 ranking\n",
      "Original query: bm25 ranking\n",
      "Preprocessed query: bm25 rank\n",
      "\n",
      "Top 3 results:\n",
      "Rank   Doc ID   Score        Content\n",
      "--------------------------------------------------------------------------------\n",
      "1      d3       0.5128       bm25 rank function wide use search engin\n",
      "2      d9       0.1536       student implement bm25 compar tfidf\n",
      "3      d14      0.1284       rerank model reorder bm25 candid use transform\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    \"library workshop\",\n",
    "    \"dog cat\",\n",
    "    \"search retrieval\",\n",
    "    \"bm25 ranking\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    results = search_and_rank(query, vocabulary, idf, doc_vectors, preprocessor, documents, top_k=5)\n",
    "    \n",
    "    print(f\"\\nTop {len(results)} results:\")\n",
    "    if results:\n",
    "        print(f\"{'Rank':<6} {'Doc ID':<8} {'Score':<12} {'Content'}\")\n",
    "        print(\"-\" * 80)\n",
    "        for rank, (doc_id, score) in enumerate(results, 1):\n",
    "            doc_content = next(d['contents'] for d in documents if d['id'] == doc_id)\n",
    "            content_preview = doc_content[:60] + \"...\" if len(doc_content) > 60 else doc_content\n",
    "            print(f\"{rank:<6} {doc_id:<8} {score:<12.4f} {content_preview}\")\n",
    "    else:\n",
    "        print(\"No matching documents found\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b469fd",
   "metadata": {},
   "source": [
    "# Interactive query !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1ad9561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_search():\n",
    "    \"\"\"Interactive search interface\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ðŸ”Ž TF-IDF Cosine Similarity Search\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Commands:\")\n",
    "    print(\"  - Enter a query to search\")\n",
    "    print(\"  - Type 'quit' or 'exit' to stop\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"Enter query: \").strip()\n",
    "        \n",
    "        if query.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"ðŸ‘‹ Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if not query:\n",
    "            print(\"âš ï¸  Please enter a query\\n\")\n",
    "            continue\n",
    "        \n",
    "        results = search_and_rank(query, vocabulary, idf, doc_vectors, preprocessor, documents, top_k=10)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Found {len(results)} matching documents:\")\n",
    "        if results:\n",
    "            print(f\"{'Rank':<6} {'Doc ID':<8} {'Score':<12} {'Content'}\")\n",
    "            print(\"-\" * 80)\n",
    "            for rank, (doc_id, score) in enumerate(results, 1):\n",
    "                doc_content = next(d['contents'] for d in documents if d['id'] == doc_id)\n",
    "                print(f\"{rank:<6} {doc_id:<8} {score:<12.4f} {doc_content}\")\n",
    "        else:\n",
    "            print(\"No matching documents found\")\n",
    "        print(\"\\n\" + \"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d2619f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ”Ž TF-IDF Cosine Similarity Search\n",
      "================================================================================\n",
      "Commands:\n",
      "  - Enter a query to search\n",
      "  - Type 'quit' or 'exit' to stop\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ðŸ” Searching for: dog\n",
      "================================================================================\n",
      "Original query: dog\n",
      "Preprocessed query: dog\n",
      "\n",
      "ðŸ“Š Found 4 matching documents:\n",
      "Rank   Doc ID   Score        Content\n",
      "--------------------------------------------------------------------------------\n",
      "1      d7       0.3102       dog cat slept couch\n",
      "2      d15      0.2804       dog snif cat ignor mous\n",
      "3      d2       0.2371       friendli dog play fetch river\n",
      "4      d12      0.2371       dog loyal companion long hike\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âš ï¸  Please enter a query\n",
      "\n",
      "================================================================================\n",
      "ðŸ” Searching for: Escape\n",
      "================================================================================\n",
      "Original query: Escape\n",
      "Preprocessed query: escap\n",
      "\n",
      "ðŸ“Š Found 0 matching documents:\n",
      "No matching documents found\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âš ï¸  Please enter a query\n",
      "\n",
      "âš ï¸  Please enter a query\n",
      "\n",
      "âš ï¸  Please enter a query\n",
      "\n",
      "âš ï¸  Please enter a query\n",
      "\n",
      "âš ï¸  Please enter a query\n",
      "\n",
      "âš ï¸  Please enter a query\n",
      "\n",
      "ðŸ‘‹ Goodbye!\n"
     ]
    }
   ],
   "source": [
    "interactive_search()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boolean-retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
